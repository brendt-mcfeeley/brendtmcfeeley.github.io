---
layout: essay
type: essay
title: Autonomous Cars...1 or 10?
date: 2017-05-02
labels:
  - Software Engineering
  - Ethics
  - Autonomous Cars
---

# What is "ethics" in the context of software engineering?
The basis of the ethics of software engineering starts off in the [ACM Software Engineering Code of Ethics and Professional Practice](http://www.acm.org/about/se-code) section.
To me, ethics is the professionalism that software engineers must exhibit at all times when creating code. They must write and execute code that will
help humans figure out the best way to live. In a brief summary, to be ethical in software engineering a person must write code that will
improve the lives of others with the least amount of diminishing return.

<p align="center">
<img src="../images/acars.jpg" height="325" width="700">
</p>

## Autonomous Cars In Our Future
There is no doubt that most people are aware of autonomous cars or self driving cars. People can also agree that our world is headed into a more autonomous direction.
People think of autonomous cars as an amazing thing that will help save people, but will they really? One thing people overthink about autonomous cars is the ethics of it.
Of course these cars are designed to be as safe as possible and save lives, but they can not save every life. The main argument behind the ethics of autonomous car programming is...
should the cars be programmed to reduce loss of life, or save the life of the driver?

## Main Ethical Argument Against Autonomous Cars
The main ethical argument against autonomous cars is how will engineers handle the loss of life? There are three main scenarios.

* A group of 10 pedestraisn people in front of the car and it will swerve and hit a single person. Saving a group of random pedestrians and killing one person.
* A single person in front of the car and the car running into a barrier, killing the passenger(s) inside and saving the pedestrian.
* A group of 10 pedestrians in front of the car and the car running into the barrier, killing the passenger(s) inside, saving the 10 pedestrians.

From these three scenarios, groups of random people median aged 30 were asked if the cars should be programmed to swerve, stay on path, or be randomly generated by the algorithm.
The general consensus was that saving more lives was a priority. But there is not a convincing enough percent that can definitively say there is one right answer.
Many people also do not want to risk their lives in order to save others. Humans can be very selfish by nature. The people surveyed were also asked if they would
buy an autonomous vehicle if it meant they were programmed to give up the passenger(s) lives instead of others. The participants actively said they did not want to be
in a car that was programmed to kill them.

## My Personal Opinion
As stated in the article Tesla's current system of car automation may be the key to solving the ethics problem. To activate Tesla's automated cruise control the driver
must make the decision in order to give the system full control of the driving. Maybe in the future humans won't have access to fully autonomous cars, but semi modular where
the driver will have the make the decision. This will but the full weight and consequences of the autonomous car on the person driving the car. You may be able to set how the
system handles different situations. And if it ever comes down to where the car must make the decision, the person who set the system is completely in charge of all the 
consequences of what happened because they were the one that initiated the autonomous driving.
